---
title: "Database Indexing for Query Performance"
description: "From 5-second queries to sub-100ms with strategic indexes"
type: "Case Study"
date: "2025-03-03"
---

How to identify slow queries, design effective indexes, and avoid common indexing pitfalls. Database performance directly impacts user experience and operational costs.

## The Problem

- Daily reports taking 5+ seconds to load; users timing out.
- No query monitoring; we found slow queries only by accident.
- Indexes everywhere but wrong ones; random reads as slow as sequential scans.
- Migrations adding indexes without testing impact; causing production issues.

## Index Design Principles

### 1. B-Tree Indexes (Most Common)

```sql
-- Single-column index
CREATE INDEX idx_users_email ON users(email);

-- Composite index (order matters!)
CREATE INDEX idx_orders_user_created
  ON orders(user_id, created_at DESC);

-- Covering index (include all needed columns)
CREATE INDEX idx_orders_covering
  ON orders(user_id, created_at)
  INCLUDE (total, status);
```

### 2. Query Patterns → Index Strategy

| Pattern         | Index Type               | Example                     |
| --------------- | ------------------------ | --------------------------- |
| WHERE + sorting | Composite (column, sort) | `(status, created_at DESC)` |
| JOINs           | Foreign key column       | `(user_id)`                 |
| Range queries   | Column with range op     | `(date)` for `BETWEEN`      |
| LIKE prefix     | First column             | `(name)` for `LIKE 'John%'` |

### 3. What NOT to Index

- [ ] Columns with low cardinality (gender, boolean).
- [ ] Columns rarely used in WHERE/JOIN.
- [ ] Columns in SELECT that aren't used for filtering.
- [ ] Redundant indexes (multiple on same columns).

## Monitoring & Optimization

```sql
-- Find slow queries (PostgreSQL)
SELECT query, calls, mean_exec_time, max_exec_time
FROM pg_stat_statements
WHERE mean_exec_time > 100
ORDER BY mean_exec_time DESC;

-- Analyze query plan
EXPLAIN ANALYZE
  SELECT * FROM orders
  WHERE user_id = 42 AND created_at > now() - interval '30 days';
```

Look for sequential scans where index scans are expected.

## Checklist

- [x] Identify slow queries via monitoring (New Relic, DataDog, Prometheus).
- [x] Analyze execution plans before adding indexes.
- [x] Create composite indexes matching query patterns.
- [x] Use covering indexes to avoid table lookups.
- [x] Avoid indexes on low-cardinality columns.
- [ ] Implement index maintenance (rebuilds, defrags).
- [ ] Set up automated slow query alerts.

## Results

- Average report load time: 5.2s → 0.08s (65x faster).
- Database CPU usage: 78% → 32%.
- Infrastructure cost: saved 40% on compute.
- User satisfaction: "reports actually work now."

## Next

- Implement partial indexes for specific data subsets.
- Build automatic index recommendation engine.
